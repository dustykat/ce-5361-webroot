{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hydrological Data Analysis and Visualization Toolkit\n",
    "\n",
    "- *Author*: Moise Baraka, Ph.D. Student in CECE Water Resources, Texas Tech University\n",
    "- *Date*: 02/21/2024\n",
    "- *Supervised by* Theodore Cleveland, Ph.D. CECE Water Resources, Associate Professor, Texas Tech University\n",
    "- *class of* spring 2024 in Surface Water Hydrology\n",
    "\n",
    "- Description:\n",
    "*This toolkit provides a collection of functions for retrieving, processing, analyzing, and visualizing hydrological data from the USGS web server. It includes modules for retrieving rating curve data, fitting it, computing statistical measures, generating histograms, and plotting various hydrological data attributes. The program allows users to input station codes to retrieve specific data and provides visualizations for any station monitored by the USGS program.*\n",
    "---\n",
    "\n",
    "## STREAMFLOW DATA RETRIEVAL\n",
    "\n",
    "- **Step 1: Input Collection**\n",
    "\n",
    "The script prompts the user to input the USGS station ID, start date, and end date.\n",
    "\n",
    "- **Step 2: Directory Selection**\n",
    "\n",
    "The user is prompted to input the directory where the data will be saved. If no directory is provided, it defaults to a predefined directory, which must have been defined in the script.\n",
    "\n",
    "- **Step 3: URL Construction**\n",
    "\n",
    "The script constructs a URL using the provided station ID, start date, and end date. This URL is used to retrieve the data from the USGS website.\n",
    "\n",
    "- **Step 4: Data Retrieval**\n",
    "\n",
    "The script downloads the data from the constructed URL. During the download process, it displays a progress bar or percentage showing the download progress.\n",
    "\n",
    "- **Step 5: Data Saving**\n",
    "\n",
    "The downloaded data is saved to the specified directory with a filename indicating the station code and data type.\r\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import re\n",
    "import urllib.request\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def get_date_input(prompt):\n",
    "    while True:\n",
    "        date_input = input(prompt)\n",
    "        # Validate date format\n",
    "        if re.match(r'^\\d{4}-\\d{2}-\\d{2}$', date_input):\n",
    "            return date_input\n",
    "        else:\n",
    "            print(\"Invalid date format. Please use yyyy-mm-dd format.\")\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def get_save_directory_input(default_directory):\n",
    "    while True:\n",
    "        save_directory = input(f\"Enter the directory to save the data (press Enter to use default directory {default_directory}): \")\n",
    "        if not save_directory:\n",
    "            return default_directory\n",
    "        # Validate directory exists\n",
    "        elif os.path.isdir(save_directory):\n",
    "            return save_directory\n",
    "        else:\n",
    "            print(\"Directory does not exist. Please enter a valid directory.\")\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def build_url1(station_code, start_date, end_date):\n",
    "    base_url = 'https://nwis.waterdata.usgs.gov/nwis/dv?referred_module=sw&search_site_no='\n",
    "    query_params = '&search_site_no_match_type=exact&site_tp_cd=OC&site_tp_cd=OC-CO&site_tp_cd=ES&site_tp_cd=' \\\n",
    "                   'LK&site_tp_cd=ST&site_tp_cd=ST-CA&site_tp_cd=ST-DCH&site_tp_cd=ST-TS&index_pmcode_00060=1' \\\n",
    "                   '&group_key=NONE&sitefile_output_format=html_table&column_name=agency_cd&column_name=site_no' \\\n",
    "                   '&column_name=station_nm&range_selection=date_range&begin_date=' + start_date + '&end_date=' + end_date + \\\n",
    "                   '&format=rdb&date_format=YYYY-MM-DD&rdb_compression=value&list_of_search_criteria=search_site_no%2Csite_tp_cd%2Crealtime_parameter_selection'\n",
    "\n",
    "    return base_url + station_code + query_params\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Retrieve and save data from a URL, and return the filename\n",
    "def retrieve_and_save_data(url, filename):\n",
    "    print(\"\\nDownloading data from:\", url , '\\n')\n",
    "    response = urllib.request.urlopen(url)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    downloaded = 0\n",
    "    chunk_size = 1024\n",
    "    start_time = time.time()  # Record start time\n",
    "    with open(filename, 'wb') as file:\n",
    "        while True:\n",
    "            chunk = response.read(chunk_size)\n",
    "            if not chunk:\n",
    "                break\n",
    "            file.write(chunk)\n",
    "            downloaded += len(chunk)\n",
    "            if total_size > 0:\n",
    "                progress = downloaded / total_size * 100\n",
    "            else:\n",
    "                # Assume 1.2 seconds download time if total_size is zero\n",
    "                elapsed_time = time.time() - start_time\n",
    "                progress = min(100, elapsed_time / 1.2 * 100)\n",
    "            print(f\"Estimated downloading progress: {progress:.1f}%\\r\", end='')\n",
    "    print(\"\\nData saved to:\", filename)\n",
    "    return filename\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "#                          Define the inputs\n",
    "#--------------------------------------------------------------------------\n",
    "print(\" ------------------------------------------\",\n",
    "        \"\\n Please provide the following information:\",\n",
    "        \"\\n ------------------------------------------\")\n",
    "\n",
    "station_code = '07297910'\n",
    "start_date = '1936-01-01'\n",
    "end_date = '2024-02-01'\n",
    "# activate code below and suppress above 3 lines for interactive\n",
    "#station_code = input('- USGS station ID: ')\n",
    "#start_date = get_date_input('- Start Date (yyyy-mm-dd): ')\n",
    "#end_date = get_date_input('- End Date (yyyy-mm-dd): ')\n",
    "\n",
    "\n",
    "\n",
    "#--------- !!! Define the directory where the data will be saved !!! -----------\n",
    "default_directory = r\"C:\\Users\\mbaraka\\OneDrive - Texas Tech University\\Thesis file\"  # To be defined!\n",
    "\n",
    "#save_directory = get_save_directory_input(default_directory)\n",
    "save_directory = './' # suppress and actiovate above for interactive\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "#        Define the base URLs for data retrieval from Website 1\n",
    "#--------------------------------------------------------------------------\n",
    "url1 = build_url1(station_code, start_date, end_date)\n",
    "\n",
    "# Retrieve and save data from Website 1\n",
    "filename1 = retrieve_and_save_data(url1, os.path.join(save_directory, f'USGS_Data_for_{station_code}.txt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATISTICS, HISTOGRAM AND FLOW DURATION CURVE\n",
    "\n",
    "- **Data Processing:**\n",
    "\n",
    "To begin with, the script processes text data saved previously, creating a DataFrame. It extracts relevant information such as agency code, site number, datetime, flow rate, and flag.\n",
    "\n",
    "- **Statistical Analysis:**\n",
    "  \n",
    "The script performs statistical analysis on the flow rate data, calculating various metrics like median, mean, standard deviation, variance, minimum, maximum, quartiles, and interquartile range. It identifies and counts outliers based on the interquartile range method.\n",
    "\n",
    "- **Plotting:**\n",
    "\n",
    "The script plots two types of graphs:\n",
    " 1. Flow Frequency Histogram with KDE (Kernel Density Estimation):\n",
    "\n",
    "Plots the distribution of flow rates against frequency. Uses Kernel Density Estimation (KDE) for smooth estimation of the probability density function.\n",
    "\n",
    "$$ P(x) = \\frac{1}{n h} \\sum_{i=1}^{n} K\\left(\\frac{x-x_i}{h}\\right) $$\n",
    "\n",
    "where $P(x)$ is the density estimate at point $x$, $n$ is the number of data points, $h$ is the bandwidth, $x_i$ are the data points, and $K$ is the kernel function.\n",
    "    \n",
    " 2. Flow Duration Curve (FDC) with Weibull formula and legend:\n",
    "\n",
    "Plots the flow rate against the probability of exceedance or equality. Computes the cumulative probability using the Gringorten method, a generalized version of the Weibull formula, defined as follows:\n",
    "$$ P(X \\geq x) = \\left(1 - \\left(\\frac{i-0.4}{n+0.2}\\right)\\right) \\times 100 $$\n",
    "\n",
    "where $P(X \\geq x)$ is the cumulative probability of exceeding or equaling $x$, $i$ is the rank of the data point, and $n$ is the total number of data points.\n",
    "\n",
    "\n",
    "*Note: Both plots are customized with appropriate labels, titles, gridlines, and legends.*\n",
    "\n",
    "- **Outputs:**\n",
    "  \n",
    "The script generates CSV files containing processed data and statistical analysis results. It also saves PNG images of the flow frequency histogram and flow duration curve.\n",
    "\n",
    "- **Libraries Used:**\n",
    "  \n",
    "    1. pandas: For data manipulation and analysis.\n",
    "    2. numpy: For mathematical operations.\n",
    "    3. matplotlib.pyplot: For plotting graphs.\n",
    "    4. seaborn: For enhanced data visualization.\n",
    "    5. io: For handling file I/O operations.\r\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import io\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Process data from a text file and return a cleaned DataFrame for Website 1\n",
    "def process_website1_data(filename, station_code):\n",
    "    data = []\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(\"USGS\"):\n",
    "                parts = line.split(\"\\t\")\n",
    "                agency_cd, site_no, datetime, flow_rate, flag = parts[:5]\n",
    "                data.append([agency_cd, site_no, datetime, flow_rate, flag])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['agency_cd', 'site_no', 'datetime', 'flow_rate', 'flag'])\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')\n",
    "    df['flow_rate'] = pd.to_numeric(df['flow_rate'], errors='coerce')\n",
    "    df.set_index('datetime', inplace=True)\n",
    "    \n",
    "    # Filter and keep rows where 'flag' is not equal to \"P\"\n",
    "    df = df[df['flag'] != 'P\\n']\n",
    "    \n",
    "    df.dropna(subset=['flow_rate'], inplace=True)\n",
    "\n",
    "    csv_filename1 = os.path.join(save_directory, f'{station_code}_flow_data.csv')\n",
    "    df.to_csv(csv_filename1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def analyze_data(df):\n",
    "    \"\"\"\n",
    "    Performs statistical analysis on the flow rate data and saves the results to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing flow rate data.\n",
    "    \"\"\"\n",
    "    sample_size = len(df)\n",
    "    median = df['flow_rate'].median()\n",
    "    mean = df['flow_rate'].mean()\n",
    "    std = df['flow_rate'].std()\n",
    "    variance = df['flow_rate'].var()\n",
    "    minimum = df['flow_rate'].min()\n",
    "    maximum = df['flow_rate'].max()\n",
    "    first_quartile = df['flow_rate'].quantile(0.25)\n",
    "    third_quartile = df['flow_rate'].quantile(0.75)\n",
    "    interquartile_range = third_quartile - first_quartile\n",
    "    \n",
    "    # Calculate number of outliers\n",
    "    outliers = df[(df['flow_rate'] < first_quartile - 1.5 * interquartile_range) | (df['flow_rate'] > third_quartile + 1.5 * interquartile_range)]\n",
    "    num_outliers = len(outliers)\n",
    "\n",
    "    # Display statistics\n",
    "    print(\"--------- Statistics: ----------\\n\")\n",
    "    print(f\"-  Sample Size: {sample_size}\")\n",
    "    print(f\"-  Median: {median:.2f}\")\n",
    "    print(f\"-  Mean: {mean:.2f}\")\n",
    "    print(f\"-  Standard Deviation: {std:.2f}\")\n",
    "    print(f\"-  Variance: {variance:.2f}\")\n",
    "    print(f\"-  Minimum: {minimum:.2f}\")\n",
    "    print(f\"-  Maximum: {maximum:.2f}\")\n",
    "    print(f\"-  First Quartile: {first_quartile:.2f}\")\n",
    "    print(f\"-  Third Quartile: {third_quartile:.2f}\")\n",
    "    print(f\"-  Interquartile Range: {interquartile_range:.2f}\")\n",
    "    print(f\"-  Number of Outliers: {num_outliers}\")\n",
    "    print()\n",
    "    \n",
    "    # Create DataFrame for statistics\n",
    "    statistics_df = pd.DataFrame({\n",
    "        'Statistic': ['Sample Size', 'Median', 'Mean', 'Standard Deviation', 'Variance', 'Minimum', 'Maximum', 'First Quartile', 'Third Quartile', 'Interquartile Range', 'Number of Outliers'],\n",
    "        'Value': [sample_size, median, mean, std, variance, minimum, maximum, first_quartile, third_quartile, interquartile_range, num_outliers]\n",
    "    })\n",
    "\n",
    "    # Save statistics to CSV file\n",
    "    statistics_filename = os.path.join(save_directory, f'{station_code}_statistics.csv')\n",
    "    statistics_df.to_csv(statistics_filename, index=False)\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def plot_flow_frequency_histogram(df):\n",
    "    \"\"\"\n",
    "    Plots the flow frequency histogram with a fitted KDE based on the flow rates in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing flow rate data.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    ax = sns.histplot(df['flow_rate'], bins=80, kde=True, edgecolor='black')\n",
    "    kde_color = 'red'\n",
    "    kde_alpha = 0.5\n",
    "    ax.get_lines()[0].set_color(kde_color)\n",
    "    ax.get_lines()[0].set_alpha(kde_alpha)\n",
    "    ax.set_title('Flow Frequency Histogram', fontsize=16)\n",
    "    ax.set_xlabel('Flow Rate (cfs)', fontsize=14)\n",
    "    ax.set_ylabel('Frequency', fontsize=14)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    plt.tight_layout()  # Ensure tight layout to prevent cropping of labels\n",
    "    plt.savefig(os.path.join(save_directory, f'{station_code}_flow_frequency_histogram.png'))\n",
    "    plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def plot_flow_duration_curve(df):\n",
    "    \"\"\"\n",
    "    Plots the flow duration curve (FDC).\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing flow rate data.\n",
    "    \"\"\"\n",
    "    # Sort the flow rates in descending order\n",
    "    df_sorted = df.sort_values('flow_rate', ascending=False)\n",
    "\n",
    "    # Compute the cumulative probability\n",
    "    # The generalized form proposed by Gringorten (1963) a = 0.4\n",
    "    df_sorted['cumulative_probability'] = ((np.arange(len(df_sorted))+0.6) / (len(df_sorted)+1.2)) * 100\n",
    "\n",
    "    # Plot the flow duration curve\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    ax.semilogy(df_sorted['cumulative_probability'], df_sorted['flow_rate'])\n",
    "    ax.set_title('Flow Duration Curve', fontsize=18)\n",
    "    ax.set_xlabel('Probability of exceedance or equality (\\%)', fontsize=16)\n",
    "    ax.set_ylabel('Flow Rate ($ft^3/s$)', fontsize=16)\n",
    "    ax.grid(which='both')\n",
    "\n",
    "    # Add legend with the Weibull formula\n",
    "    equation = r'$P(X \\geq x) = \\left(1 - \\left(\\frac{i-0.4}{n+0.2}\\right)\\right) \\times 100$'\n",
    "    #ax.legend(['Flow Duration Curve', f'Weibull Fit: {equation}'], bbox_to_anchor=(0.35, .95), loc='upper left', fontsize=16)\n",
    "\n",
    "    # Add text box with the Weibull formula\n",
    "    ax.text(0.25, 0.8, f'Weilbull formula: {equation}', transform=ax.transAxes, fontsize=16, verticalalignment='top', bbox=dict(facecolor='white', alpha=1))\n",
    "\n",
    "    plt.tight_layout()  # Ensure tight layout to prevent cropping of labels\n",
    "    \n",
    "    plt.savefig(os.path.join(save_directory, f'{station_code}_fdc.png'))\n",
    "    plt.show()\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "#      Preprocess the Retrieved Data and Display the Head Part of it \n",
    "#--------------------------------------------------------------------------\n",
    "df1 = process_website1_data(filename1, station_code)\n",
    "\n",
    "# Display the first few rows of data from Website 1\n",
    "print(\"Data from Website 1:\")\n",
    "print(df1.head())\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "#                                 Plotting \n",
    "#--------------------------------------------------------------------------\n",
    "# Plot the flow frequency histogram with a fitted KDE\n",
    "plot_flow_frequency_histogram(df1)\n",
    "\n",
    "# Statistical analysis\n",
    "analyze_data(df1)\n",
    "\n",
    "# Flow duration curve\n",
    "plot_flow_duration_curve(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEMPORAL PATTERN\n",
    "\n",
    "**Data Processing:**\n",
    "\n",
    "After plotting the rating curve, a script is written to process flow rate data stored in the DataFrame generated from the previous step. It calculates yearly means with standard deviations. It also performs linear regression to fit trend lines to the data.\n",
    "\n",
    "**Plotting:**\n",
    "\n",
    "Two types of plots are generated:\n",
    "   1. Yearly Moving Averages: Plots the yearly moving averages of flow rate data with error bars representing standard deviations.\n",
    "\n",
    "   2. A Trend Line (Linear Regression): Fits a trend line to the yearly means using linear regression. The equation of the trend line is of the form: $$ y = mx + c $$\n",
    "\n",
    "where $m$ is the slope (coefficient), $x$ is the year, and $c$ is the intercept.\n",
    "\n",
    "   3. Confidence Intervals: Calculates the 95% confidence interval for the trend line using the t-distribution. The formula for the margin of error is: $$ E = t \\times \\frac{s}{\\sqrt{n}} $$\n",
    "\n",
    "where $E$ is the margin of error, $t$ is the critical t-value, $s$ is the standard deviation of the sample means, and $n$ is the sample size.\n",
    "\n",
    "**Outputs:**\n",
    "\n",
    "The script generates two plots: daily flow rates and yearly means with trend lines and confidence intervals. Then the script saves the plot of yearly means as a PNG image.\n",
    "\n",
    "**Libraries Used:**\n",
    "  1. numpy: For mathematical operations.\n",
    "  2. matplotlib.pyplot: For plotting graphs.\n",
    "  3. scipy.stats.t: For computing t-values for confidence intervals.\n",
    "  4. sklearn.linear_model.LinearRegression: For performing linear regression.\n",
    " linear regression.\r\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def plot_yearly_moving_average(df):\n",
    "    \"\"\"\n",
    "    Plots the yearly moving averages of flow rate data along with a trend line.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing flow rate data.\n",
    "    \"\"\"\n",
    "    # Compute yearly moving averages\n",
    "    yearly_ma = df['flow_rate'].rolling(window=365, min_periods=1).mean()\n",
    "    \n",
    "    # Plot data and moving averages\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df.index, df['flow_rate'], label='Flow Rate', color='blue', alpha=0.5)\n",
    "    plt.plot(yearly_ma.index, yearly_ma, label='Yearly Moving Average', color='red')\n",
    "    \n",
    "    # Fit a trend line\n",
    "    trend_coef = np.polyfit(df.index.to_julian_date(), df['flow_rate'], 1)\n",
    "    trend_line = np.poly1d(trend_coef)\n",
    "    plt.plot(df.index, trend_line(df.index.to_julian_date()), label='Trend Line', linestyle='--', color='green')\n",
    "\n",
    "    plt.title('Yearly Moving Averages of Flow Rate with Trend Line')\n",
    "    plt.xlabel('Date (years)')\n",
    "    plt.ylabel('Flow Rate ($ft^3/s$)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "def plot_yearly_means_with_trend(df):\n",
    "    \"\"\"\n",
    "    Plots the yearly means of flow rate data with error bars (std) and a trend line with shaded confidence intervals.\n",
    "    NaN values in flow rate are replaced by the mean of all non-NaN flow rates,\n",
    "    and NaN values in standard deviation are replaced by the mean of all non-NaN standard deviations.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): DataFrame containing flow rate data.\n",
    "    \"\"\"\n",
    "    # Compute yearly means and standard deviations\n",
    "    yearly_means = df['flow_rate'].resample('Y').mean()\n",
    "    yearly_std = df['flow_rate'].resample('Y').std()\n",
    "\n",
    "    # Replace NaN values in flow rate with the mean of all non-NaN flow rates\n",
    "    yearly_means.fillna(yearly_means.mean(), inplace=True)\n",
    "    \n",
    "    # Replace NaN values in std with the mean of all non-NaN std\n",
    "    yearly_std.fillna(yearly_std.mean(), inplace=True)\n",
    "    \n",
    "    # Prepare data for linear regression\n",
    "    X = yearly_means.index.year.values.reshape(-1, 1)\n",
    "    y = yearly_means.values\n",
    "    \n",
    "    # Fit linear regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Compute trend line values\n",
    "    trend_values = model.predict(X)\n",
    "    \n",
    "    # Compute overall mean and standard deviation of yearly means\n",
    "    overall_mean = yearly_means.mean()\n",
    "    overall_std = yearly_means.std()\n",
    "    \n",
    "    # Compute t-value for a 95% confidence interval with n-1 degrees of freedom\n",
    "    t_value = t.ppf(0.975, len(yearly_means) - 1)\n",
    "    \n",
    "    # Compute margin of error\n",
    "    margin_of_error = t_value * overall_std / np.sqrt(len(yearly_means))\n",
    "    \n",
    "    # Compute upper and lower bounds of the confidence interval for the overall mean\n",
    "    upper_bound = trend_values + margin_of_error\n",
    "    lower_bound = trend_values - margin_of_error\n",
    "    \n",
    "    # Plot yearly means with error bars\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.errorbar(yearly_means.index, yearly_means, yerr=yearly_std, fmt='o', markersize=5, capsize=5, label='Yearly Means ± Std')\n",
    "    \n",
    "    # Plot trend line\n",
    "    plt.plot(yearly_means.index, trend_values, label=f'Trend Line: $y = {model.coef_[0]:.2f}x + ({model.intercept_:.2f})$', linestyle='-', color='green')\n",
    "    \n",
    "    # Shade confidence interval\n",
    "    plt.fill_between(yearly_means.index, lower_bound, upper_bound, color='orange', alpha=0.3, label='95\\% Confidence Interval')\n",
    "    \n",
    "    plt.title('Yearly Means of Flow Rate with Trend Line and Confidence Intervals', fontsize=16)\n",
    "    plt.xlabel('Date $(yrs)$', fontsize=16)\n",
    "    plt.ylabel('Flow Rate $(ft^3/s)$', fontsize=16)\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()  # Ensure tight layout to prevent cropping of labels\n",
    "    plt.savefig(os.path.join(save_directory, f'{station_code}_yearly_mean.png'))\n",
    "    plt.show()\n",
    "    return #yearly_means\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "#                         Moving average \n",
    "#------------------------------------------------------------------------\n",
    "plot_yearly_moving_average(df1)\n",
    "plot_yearly_means_with_trend(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Rating Curve\n",
    "\n",
    "Based on the station code, the script retrieves rating curve data from the USGS website using the station code provided as input. It then fits a rating curve equation of the form $H(Q) = a \\cdot Q^b + \\frac{1}{c}$ to the data, where $H$ is gage height and $Q$ is discharge. The fitting is performed by minimizing the residuals between the observed and predicted gage heights. The R-squared value is computed as a measure of goodness-of-fit.\n",
    "\n",
    "### Outputs:\n",
    "- Plot of the original rating curve data.\n",
    "- Plot of the fitted rating curve along with the equation and R-squared value.\n",
    "- If successful, the script also saves the fitted curve plot as a PNG file.\n",
    "\n",
    "### Functions:\n",
    "1. retrieve_rating_curve_data(station_code): Retrieves and cleans rating curve data from the USGS website.\n",
    "2. plot_original_data(df_rating): Plots the original rating curve data.\n",
    "3. objective_function(params, df_rating, equation_func): Objective function to minimize residuals and maximize R-squared.\n",
    "4. fit_rating_curve(df_rating): Fits the rating curve equation to the data using optimization.\n",
    "5. plot_fitted_curve(df_rating, params, r_squared): Plots the fitted rating curve along with the equation and R-squared value.\n",
    "6. main(station_code): Main function to execute the entire process.\n",
    "\n",
    "### Libraries Used:\n",
    "- numpy: For mathematical operations.\n",
    "- pandas: For data manipulation.\n",
    "- matplotlib.pyplot: For plotting graphs.\n",
    "- scipy.optimize.minimize: For optimization to fit the curve.\n",
    "- sklearn.metrics.r2_score: For computing the R-squared value.\n",
    "- requests: For retrieving data from the USGS website.\n",
    "om the USGS website.\r\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import r2_score\n",
    "import requests \n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Define the equation a * Q^b + c\n",
    "def rating_equation(Q, a, b, c):\n",
    "    return a * np.power(Q, b) + 1/c\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Retrieve rating curve data\n",
    "def retrieve_rating_curve_data(station_code):\n",
    "    url = f\"https://waterdata.usgs.gov/nwisweb/get_ratings?file_type=exsa&site_no={station_code}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to retrieve data for station code {station_code}.\")\n",
    "    df = pd.read_csv(response.url, skiprows=29, delimiter=\"\\t\", names=[\"INDEP\", \"SHIFT\", \"DEP\", \"STOR\"])\n",
    "    df = df[[\"INDEP\", \"DEP\"]]\n",
    "    df.columns = [\"Gage Height\", \"Discharge\"]\n",
    "    df[\"Gage Height\"] = pd.to_numeric(df[\"Gage Height\"], errors=\"coerce\")\n",
    "    df[\"Discharge\"] = pd.to_numeric(df[\"Discharge\"], errors=\"coerce\")\n",
    "    df = df.dropna()\n",
    "    df = df.sort_values(by=\"Discharge\")\n",
    "    return df\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Plot the original rating curve data\n",
    "def plot_original_data(df_rating):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(df_rating['Discharge'], df_rating['Gage Height'], label='Original data', color='steelblue')\n",
    "    plt.xlabel('Discharge $(ft^3/s)$', fontsize=14)\n",
    "    plt.ylabel('Gage Height $(ft)$', fontsize=14)\n",
    "    plt.title('Original Rating Curve Data', fontsize=16)\n",
    "    plt.grid(True)\n",
    "    plt.legend(fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Objective function to minimize R-squared\n",
    "def objective_function(params, df_rating, equation_func):\n",
    "    predicted_gage_height = equation_func(df_rating['Discharge'], *params)\n",
    "    ss_residuals = np.sum((df_rating['Gage Height'] - predicted_gage_height)**2)\n",
    "    ss_total = np.sum((df_rating['Gage Height'] - np.mean(df_rating['Gage Height']))**2)\n",
    "    \n",
    "    # Check if ss_total is close to zero\n",
    "    if ss_total < 1e-10:  # Adjust threshold as needed\n",
    "        return -1e10      # Return a large negative value to discourage such solutions\n",
    "    \n",
    "    r_squared = 1 - (ss_residuals / ss_total)\n",
    "    return -r_squared      # Minimize negative R-squared\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Fit the equation using minimization of residuals\n",
    "def fit_rating_curve(df_rating):\n",
    "    x0 = np.ones(3)  # Initial guess for parameters [a, b, c]\n",
    "    res = minimize(objective_function, x0, args=(df_rating, rating_equation), method='Nelder-Mead')\n",
    "    if res.success:\n",
    "        # Calculate predicted gage heights\n",
    "        predicted_gage_heights = rating_equation(df_rating['Discharge'], *res.x)\n",
    "        \n",
    "        # Calculate R-squared\n",
    "        r_squared = r2_score(df_rating['Gage Height'], predicted_gage_heights)\n",
    "        \n",
    "        return res.x, r_squared\n",
    "    else:\n",
    "        print(\"Fitting failed:\", res.message)  # Print out the error message\n",
    "        return None, None\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "# Plot the fitting rating curve\n",
    "def plot_fitted_curve(df_rating, params, r_squared):\n",
    "    # Define colors for scatter and curve\n",
    "    scatter_color = 'steelblue'\n",
    "    curve_color = 'darkorange'\n",
    "\n",
    "    # Create figure and axis objects\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Plot original data as scatter points\n",
    "    ax.scatter(df_rating['Discharge'], df_rating['Gage Height'], label='Original data', color=scatter_color, alpha=0.7)\n",
    "\n",
    "    # Generate fitted curve\n",
    "    Q_fit = np.linspace(df_rating['Discharge'].min(), df_rating['Discharge'].max(), 100)\n",
    "    fitted_curve = rating_equation(Q_fit, *params)\n",
    "    \n",
    "    # Plot fitted curve\n",
    "    ax.plot(Q_fit, fitted_curve, label=f'Fitted curve: $H(Q) = a \\cdot Q^b + \\\\frac{{1}}{{c}}$', color=curve_color, linewidth=3)\n",
    "\n",
    "    # Add equation and R-squared value as text box\n",
    "    equation_text = f\"$H(Q) = {params[0]:.3f} \\cdot Q^{{{params[1]:.3f}}} + \\\\frac{{1}}{{{params[2]:.3f}}}$\"\n",
    "    r_squared_text = f\"$R^2 = {r_squared:.4f}$\"\n",
    "    text_box_content = f\"{equation_text}\\n\\n{r_squared_text}\"\n",
    "    ax.text(0.55, 0.35, text_box_content, transform=ax.transAxes, fontsize=16, verticalalignment='top', bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Discharge $(ft^3/s)$', fontsize=14)\n",
    "    ax.set_ylabel('Gage Height $(ft)$', fontsize=14)\n",
    "    ax.set_title('Fitted Rating Curve', fontsize=16)\n",
    "    \n",
    "    # Add grid\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Add legend\n",
    "    ax.legend(fontsize=16)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save plot as PNG file\n",
    "    plt.savefig(f'{station_code}fitted_rating_curve.png')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "#------------------------------------------------------------------------\n",
    "#Main function to operate the script\n",
    "def main(station_code):\n",
    "    # Step 1: Retrieve and clean data\n",
    "    df_rating = retrieve_rating_curve_data(station_code)\n",
    "    \n",
    "    # Step 2: Plot original data\n",
    "    plot_original_data(df_rating)\n",
    "    \n",
    "    # Step 3: Fit the curve\n",
    "    params, r_squared = fit_rating_curve(df_rating)\n",
    "    \n",
    "    # Step 4: Plot the fitted curve\n",
    "    if params is not None:\n",
    "        plot_fitted_curve(df_rating, params, r_squared)\n",
    "    else:\n",
    "        print(\"Fitting failed. Unable to plot the fitted curve.\")\n",
    "\n",
    "#--------------------------------------------------------------------------\n",
    "#           Call the main function by the station code\n",
    "#--------------------------------------------------------------------------\n",
    "main(station_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "- U.S. Geological Survey. (1996). *Data from Selected U.S. Geological Survey National Stream Water-Quality Monitoring Networks (WQN) on CD-ROM*. Retrieved from [https://pubs.usgs.gov/dds/wqn96cd/](https://pubs.usgs.gov/dds/wqn96cd/) on 11/29/2023.\n",
    "\n",
    "- Vogel, R. M., & Fennessey, N. M. (1995). Flow duration curves II: a review of applications in water resources planning. *JAWRA Journal of the American Water Resources Association*, 31(6), 1029-1039.\n",
    "\n",
    "- Bedient, P. B. (2002). *Hydrologic and Floodplain Analysis*. Prentice Hall, Upper Saddle River, New Jersey 07458.\n",
    "\n",
    "- HydroMohsen. (2022). *Download and Visualize Daily Streamflow Data from USGS Using Python*. Retrieved from [https://www.youtube.com/watch?v=fs5BOUn8zvw](https://www.youtube.com/watch?v=fs5BOUn8zvw) on 2023-03-15.\n",
    "\n",
    "- Mohsen Tahmasebi Nasab. (2022). *Download and Visualize Daily Streamflow Data from USGS Using Python*. Retrieved from [https://colab.research.google.com/drive/1OqjB1UbUH8KwJEIG6qMCfdfJtLev5kph?usp=sharing](https://colab.research.google.com/drive/1OqjB1UbUH8KwJEIG6qMCfdfJtLev5kph?usp=sharing) on 2023-03-15.\n",
    "\n",
    "- OpenAI. (2022). *ChatGPT: Conversational AI Model*. Version 3.5. Retrieved from [https://openai.com/chatgpt](https://openai.com/chatgpt) on February 21, 2024.\n",
    "03-15.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
